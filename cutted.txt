"한문 교육용 기초 한자", "漢文 敎育用 基礎 漢字"
"한국의 수도는 [MASK]이다"

首先，我的问题正确的做法不是 seq2seq, 而是 token classification, 正如 NER 等经典问题。NER 等问题也是从韩语的语言上下文中寻找专有名词，也是需要对上下文的理解，也是 NLP 任务，也是使用 BERT 能做的更好的东西。一定程度上，这和“标记汉字词”很像：NE 词汇与日常词汇间存在泾渭分明的区别，正如汉字词汇与大韩词汇。

"""
import torch
torch.cuda.is_available()

list(labels_to_hanja_words.values())[0:250]
list(labels_to_hanja_words.values())[250:500]
labeled_inputs['train'][4181]
labeled_inputs['test'][254]

"""
