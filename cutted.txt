"한문 교육용 기초 한자", "漢文 敎育用 基礎 漢字"
"한국의 수도는 [MASK]이다"

首先，我的问题正确的做法不是 seq2seq, 而是 token classification, 正如 NER 等经典问题。NER 等问题也是从韩语的语言上下文中寻找专有名词，也是需要对上下文的理解，也是 NLP 任务，也是使用 BERT 能做的更好的东西。一定程度上，这和“标记汉字词”很像：NE 词汇与日常词汇间存在泾渭分明的区别，正如汉字词汇与大韩词汇。

"""
import torch
torch.cuda.is_available()

list(labels_to_hanja_words.values())[0:250]
list(labels_to_hanja_words.values())[250:500]
labeled_inputs['train'][4181]
labeled_inputs['test'][254]

"""
from predict import predict
predict('디두모라 하는 도마가 다른 제자들에게 말하되 우리도 주와 함께 죽으러 가자 하니라')
predict(['디두모라 하는 도마가 다른 제자들에게 말하되 우리도 주와 함께 죽으러 가자 하니라', '돌을 옮겨 놓으니 예수께서 눈을 들어 우러러 보시고 가라사대 아버 지여 내 말을 들으신 것을 감사하나이다'])
import time
import codecs
strings = []
i = 0
for line in codecs.open('data/bible_ko.tsv', 'r', 'utf-8'):
    if len(line) <= 500:
        strings.append(line.strip().split("\t")[0])
    i += 1
    if i >= 1000:
        break

strings[962]

t = time.time()
c = predict(strings)
dt = time.time() - t
dt
c[962]

s = "승정원일기는 행정과 사무, 왕명, 출납 등을 맡은 승정원의 사무를 기록한 일기이다. 단일 사료로서는 가장 방대한 양으로서 사료적 가치가 높게 평가된다. 모두 3,245책, 글자 수 2억 4,250만자다. 1960년부터 1977년까지 국사편찬위원회에서 초서체였던 승정원일기를 해서체로 고쳐쓰는 작업을 하였다. 2000년부터 2010년까지는 승정원일기 정보화사업을 진행하여 영인본 1책~111책, 127책~129책에 대한 전산화가 진행되었다. 원본 1부밖에 없는 귀중한 자료로 국보 제303호(1999.4.9)로 지정되어 있다. 이는 세계 최대 및 1차 사료로서의 가치를 인정받아 2001년 9월 유네스코세계기록유산으로 등재되었다."
strings = s.split(".")
".".join(predict(strings))
